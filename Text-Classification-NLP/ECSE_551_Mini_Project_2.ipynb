{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szE_tkWZCfdy",
        "outputId": "81b79193-6085-48cd-f9b7-250fd63438c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Reading data...\n",
            "Training data shape: (1399, 2)\n",
            "Test data shape: (600, 2)\n",
            "\n",
            "Cleaning texts...\n",
            "\n",
            "Extracting features...\n",
            "\n",
            "Initializing models...\n",
            "\n",
            "Performing cross-validation for BernoulliNB...\n",
            "Fold 1 Accuracy: 0.6321\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Brussels       0.55      0.77      0.64        70\n",
            "      London       0.62      0.57      0.60        70\n",
            "    Montreal       0.97      0.40      0.57        70\n",
            "     Toronto       0.62      0.79      0.69        70\n",
            "\n",
            "    accuracy                           0.63       280\n",
            "   macro avg       0.69      0.63      0.62       280\n",
            "weighted avg       0.69      0.63      0.62       280\n",
            "\n",
            "Fold 2 Accuracy: 0.6571\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Brussels       0.55      0.74      0.63        70\n",
            "      London       0.64      0.70      0.67        70\n",
            "    Montreal       0.97      0.49      0.65        70\n",
            "     Toronto       0.67      0.70      0.69        70\n",
            "\n",
            "    accuracy                           0.66       280\n",
            "   macro avg       0.71      0.66      0.66       280\n",
            "weighted avg       0.71      0.66      0.66       280\n",
            "\n",
            "Fold 3 Accuracy: 0.6107\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Brussels       0.55      0.81      0.66        70\n",
            "      London       0.50      0.50      0.50        70\n",
            "    Montreal       1.00      0.41      0.59        70\n",
            "     Toronto       0.64      0.71      0.68        70\n",
            "\n",
            "    accuracy                           0.61       280\n",
            "   macro avg       0.67      0.61      0.61       280\n",
            "weighted avg       0.67      0.61      0.61       280\n",
            "\n",
            "Fold 4 Accuracy: 0.6786\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Brussels       0.58      0.76      0.65        70\n",
            "      London       0.70      0.61      0.66        70\n",
            "    Montreal       0.93      0.57      0.71        70\n",
            "     Toronto       0.64      0.77      0.70        70\n",
            "\n",
            "    accuracy                           0.68       280\n",
            "   macro avg       0.71      0.68      0.68       280\n",
            "weighted avg       0.71      0.68      0.68       280\n",
            "\n",
            "Fold 5 Accuracy: 0.6201\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Brussels       0.50      0.76      0.60        70\n",
            "      London       0.68      0.43      0.53        70\n",
            "    Montreal       0.97      0.47      0.63        70\n",
            "     Toronto       0.60      0.83      0.70        69\n",
            "\n",
            "    accuracy                           0.62       279\n",
            "   macro avg       0.69      0.62      0.61       279\n",
            "weighted avg       0.69      0.62      0.61       279\n",
            "\n",
            "\n",
            "BernoulliNB Mean CV Score: 0.6397 (±0.0249)\n",
            "\n",
            "Performing cross-validation for RandomForest...\n",
            "Fold 1 Accuracy: 0.6393\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Brussels       0.55      0.77      0.64        70\n",
            "      London       0.56      0.67      0.61        70\n",
            "    Montreal       0.97      0.50      0.66        70\n",
            "     Toronto       0.69      0.61      0.65        70\n",
            "\n",
            "    accuracy                           0.64       280\n",
            "   macro avg       0.69      0.64      0.64       280\n",
            "weighted avg       0.69      0.64      0.64       280\n",
            "\n",
            "Fold 2 Accuracy: 0.7071\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Brussels       0.68      0.69      0.68        70\n",
            "      London       0.59      0.86      0.70        70\n",
            "    Montreal       0.95      0.59      0.73        70\n",
            "     Toronto       0.77      0.70      0.73        70\n",
            "\n",
            "    accuracy                           0.71       280\n",
            "   macro avg       0.75      0.71      0.71       280\n",
            "weighted avg       0.75      0.71      0.71       280\n",
            "\n",
            "Fold 3 Accuracy: 0.6643\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Brussels       0.60      0.80      0.68        70\n",
            "      London       0.57      0.81      0.67        70\n",
            "    Montreal       0.97      0.49      0.65        70\n",
            "     Toronto       0.76      0.56      0.64        70\n",
            "\n",
            "    accuracy                           0.66       280\n",
            "   macro avg       0.73      0.66      0.66       280\n",
            "weighted avg       0.73      0.66      0.66       280\n",
            "\n",
            "Fold 4 Accuracy: 0.7000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Brussels       0.59      0.69      0.64        70\n",
            "      London       0.67      0.76      0.71        70\n",
            "    Montreal       0.93      0.61      0.74        70\n",
            "     Toronto       0.70      0.74      0.72        70\n",
            "\n",
            "    accuracy                           0.70       280\n",
            "   macro avg       0.73      0.70      0.70       280\n",
            "weighted avg       0.73      0.70      0.70       280\n",
            "\n",
            "Fold 5 Accuracy: 0.6667\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Brussels       0.53      0.71      0.61        70\n",
            "      London       0.65      0.64      0.65        70\n",
            "    Montreal       0.90      0.63      0.74        70\n",
            "     Toronto       0.70      0.68      0.69        69\n",
            "\n",
            "    accuracy                           0.67       279\n",
            "   macro avg       0.70      0.67      0.67       279\n",
            "weighted avg       0.70      0.67      0.67       279\n",
            "\n",
            "\n",
            "RandomForest Mean CV Score: 0.6755 (±0.0250)\n",
            "\n",
            "Training final model...\n",
            "Generating predictions...\n",
            "\n",
            "Submission saved to /content/gdrive/MyDrive/ECSE_551/submission.csv\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import drive\n",
        "from scipy import sparse\n",
        "import re\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Define file paths\n",
        "train_path = '/content/gdrive/MyDrive/ECSE_551/Train.csv'\n",
        "test_path = '/content/gdrive/MyDrive/ECSE_551/Test.csv'\n",
        "output_path = '/content/gdrive/MyDrive/ECSE_551/submission.csv'\n",
        "\n",
        "class EnhancedBernoulliNB:\n",
        "    def __init__(self, alpha=1.0):\n",
        "        self.alpha = alpha\n",
        "        self.classes_ = None\n",
        "        self.class_priors_ = None\n",
        "        self.feature_probabilities_ = None\n",
        "        self.class_weights = {\n",
        "            'Brussels': 1.2,\n",
        "            'London': 1.1,\n",
        "            'Montreal': 1.2,\n",
        "            'Toronto': 1.0\n",
        "        }\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if sparse.issparse(X):\n",
        "            X = X.toarray()\n",
        "\n",
        "        self.classes_ = np.unique(y)\n",
        "        n_samples = X.shape[0]\n",
        "        n_features = X.shape[1]\n",
        "\n",
        "        # Apply class weights\n",
        "        class_counts = np.array([np.sum(y == c) for c in self.classes_])\n",
        "        weighted_counts = np.array([class_counts[i] * self.class_weights.get(c, 1.0)\n",
        "                                  for i, c in enumerate(self.classes_)])\n",
        "\n",
        "        self.class_priors_ = (weighted_counts + self.alpha) / (n_samples + self.alpha * len(self.classes_))\n",
        "        self.feature_probabilities_ = np.zeros((len(self.classes_), n_features))\n",
        "\n",
        "        for i, c in enumerate(self.classes_):\n",
        "            X_c = X[y == c]\n",
        "            feature_counts = X_c.sum(axis=0)\n",
        "            # Apply adaptive smoothing based on class frequency\n",
        "            smooth_factor = self.alpha * (1.0 / max(class_counts[i], 1)) ** 0.5\n",
        "            self.feature_probabilities_[i] = (feature_counts + smooth_factor) / (class_counts[i] + 2 * smooth_factor)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if sparse.issparse(X):\n",
        "            X = X.toarray()\n",
        "\n",
        "        log_probs = np.zeros((X.shape[0], len(self.classes_)))\n",
        "\n",
        "        for i, c in enumerate(self.classes_):\n",
        "            log_probs[:, i] = np.log(self.class_priors_[i])\n",
        "            log_probs[:, i] += np.sum(X * np.log(self.feature_probabilities_[i]), axis=1)\n",
        "            log_probs[:, i] += np.sum((1 - X) * np.log(1 - self.feature_probabilities_[i]), axis=1)\n",
        "\n",
        "        # Numerical stability\n",
        "        log_probs -= np.max(log_probs, axis=1)[:, np.newaxis]\n",
        "        probs = np.exp(log_probs)\n",
        "        probs /= np.sum(probs, axis=1)[:, np.newaxis]\n",
        "\n",
        "        return probs\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.classes_[np.argmax(self.predict_proba(X), axis=1)]\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Enhanced text cleaning function\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove URLs and Reddit formatting\n",
        "    text = re.sub(r'http\\S+|www\\S+|\\[.*?\\]\\(.*?\\)', ' ', text)\n",
        "    text = re.sub(r'/r/\\w+|/u/\\w+', ' ', text)\n",
        "\n",
        "    # Remove HTML entities\n",
        "    text = re.sub(r'&amp;|&lt;|&gt;', ' ', text)\n",
        "\n",
        "    # Remove bot signatures\n",
        "    text = re.sub(r'i am a bot.*|please contact the moderators.*',\n",
        "                 '', text, flags=re.IGNORECASE | re.DOTALL)\n",
        "\n",
        "    # Clean special characters but keep meaningful punctuation\n",
        "    text = re.sub(r'[^\\w\\s.,!?-]', ' ', text)\n",
        "\n",
        "    # Normalize whitespace\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "def create_city_features(text):\n",
        "    \"\"\"Extract city-specific features\"\"\"\n",
        "    text = text.lower()\n",
        "    features = []\n",
        "\n",
        "    # City-specific keywords\n",
        "    city_patterns = {\n",
        "        'toronto': ['toronto', 'gta', 'ttc', 'ontario', 'dundas', 'yonge'],\n",
        "        'montreal': ['montreal', 'quebec', 'stm', 'plateau', 'metro'],\n",
        "        'london': ['london', 'tube', 'underground', 'oyster', 'thames', 'uk'],\n",
        "        'brussels': ['brussels', 'belgium', 'belgian', 'eu', 'european']\n",
        "    }\n",
        "\n",
        "    for city_words in city_patterns.values():\n",
        "        count = sum(1 for word in city_words if word in text)\n",
        "        features.append(count)\n",
        "\n",
        "    return features\n",
        "\n",
        "def perform_cross_validation(X, y, model, k=5):\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
        "        X_train_fold = X[train_index]\n",
        "        X_val_fold = X[val_index]\n",
        "        y_train_fold = y[train_index]\n",
        "        y_val_fold = y[val_index]\n",
        "\n",
        "        model.fit(X_train_fold, y_train_fold)\n",
        "        y_pred = model.predict(X_val_fold)\n",
        "\n",
        "        accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "        scores.append(accuracy)\n",
        "\n",
        "        print(f\"Fold {fold + 1} Accuracy: {accuracy:.4f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_val_fold, y_pred))\n",
        "\n",
        "    return scores\n",
        "\n",
        "def main():\n",
        "    # Read data\n",
        "    print(\"Reading data...\")\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    test_df = pd.read_csv(test_path)\n",
        "\n",
        "    print(f\"Training data shape: {train_df.shape}\")\n",
        "    print(f\"Test data shape: {test_df.shape}\")\n",
        "\n",
        "    # Clean texts\n",
        "    print(\"\\nCleaning texts...\")\n",
        "    train_texts = [clean_text(text) for text in train_df.iloc[:, 0]]\n",
        "    test_texts = [clean_text(text) for text in test_df['body']]\n",
        "\n",
        "    # Feature extraction\n",
        "    print(\"\\nExtracting features...\")\n",
        "\n",
        "    # Binary features\n",
        "    count_vec = CountVectorizer(\n",
        "        max_features=3000,\n",
        "        binary=True,\n",
        "        ngram_range=(1, 2),\n",
        "        min_df=2,\n",
        "        stop_words='english'\n",
        "    )\n",
        "\n",
        "    X_train_binary = count_vec.fit_transform(train_texts)\n",
        "    X_test_binary = count_vec.transform(test_texts)\n",
        "\n",
        "    # Get labels\n",
        "    y_train = train_df.iloc[:, 1]\n",
        "\n",
        "    # Initialize models\n",
        "    print(\"\\nInitializing models...\")\n",
        "    bernoulli_nb = EnhancedBernoulliNB(alpha=0.1)\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=200,\n",
        "        max_depth=20,\n",
        "        class_weight='balanced',\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Cross-validation\n",
        "    print(\"\\nPerforming cross-validation for BernoulliNB...\")\n",
        "    nb_scores = perform_cross_validation(X_train_binary, y_train, bernoulli_nb)\n",
        "    print(f\"\\nBernoulliNB Mean CV Score: {np.mean(nb_scores):.4f} (±{np.std(nb_scores):.4f})\")\n",
        "\n",
        "    print(\"\\nPerforming cross-validation for RandomForest...\")\n",
        "    rf_scores = perform_cross_validation(X_train_binary, y_train, rf)\n",
        "    print(f\"\\nRandomForest Mean CV Score: {np.mean(rf_scores):.4f} (±{np.std(rf_scores):.4f})\")\n",
        "\n",
        "    # Train final model\n",
        "    print(\"\\nTraining final model...\")\n",
        "    best_model = bernoulli_nb if np.mean(nb_scores) > np.mean(rf_scores) else rf\n",
        "    best_model.fit(X_train_binary, y_train)\n",
        "\n",
        "    # Generate predictions\n",
        "    print(\"Generating predictions...\")\n",
        "    predictions = best_model.predict(X_test_binary)\n",
        "\n",
        "    # Create submission\n",
        "    submission = pd.DataFrame({\n",
        "        'id': test_df['id'],\n",
        "        'subreddit': predictions\n",
        "    })\n",
        "\n",
        "    submission.to_csv(output_path, index=False)\n",
        "    print(f\"\\nSubmission saved to {output_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}